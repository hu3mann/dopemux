##### >>> BEGIN FILE: uberslicer/__init__.py <<< #####
import importlib, yaml, pathlib
from uberslicer.utils import log_dev

PLUGIN_DIR = pathlib.Path("plugins")

def load_plugins():
    for yml in PLUGIN_DIR.glob("*/plugin.yaml"):
        meta = yaml.safe_load(yml.read_text())
        mod = importlib.import_module(meta["entrypoint"].rstrip(".py").replace("/", "."))
        log_dev({"action":"plugin_loaded","name":meta["name"]})
        yield meta["name"], mod.run

##### <<< END FILE:   uberslicer/__init__.py <<< #####

##### >>> BEGIN FILE: uberslicer/doctor.py <<< #####
"""
Sanity checker for folder layout, config keys, and required files.
Called via `dopemux doctor`.
"""

from pathlib import Path
import yaml
import sys

# Match your config.yaml structure
REQUIRED_CONFIG_KEYS = [
    "dopemux.paths.tagged",
    "dopemux.paths.patch_dir",
    "dopemux.paths.outputs",
    "dopemux.paths.devlog",
    "dopemux.paths.audit",
    "dopemux.schema.file",
    "dopemux.auditor.block_review_tag",
]

REQUIRED_DIRS = [
    "tagged",
    "tagged/patch",
    "logs",
    "schema",
]

REQUIRED_FILES = [
    "schema/extraction-schema.json",
    "config.yaml",
]

def warn(msg):
    print(f"‚ùå  {msg}")

def ok(msg):
    print(f"‚úÖ  {msg}")

def load_cfg():
    try:
        with open("config.yaml") as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        warn("config.yaml not found at repo root.")
        sys.exit(1)

def check_keys(cfg):
    # flatten nested dict to dot-keys
    flat = {}
    def _flatten(prefix, mapping):
        for k, v in mapping.items():
            key = f"{prefix}.{k}" if prefix else k
            flat[key] = v
            if isinstance(v, dict):
                _flatten(key, v)
    _flatten("", cfg)
    missing = [k for k in REQUIRED_CONFIG_KEYS if k not in flat]
    if missing:
        warn(f"Missing config keys: {', '.join(missing)}")
    else:
        ok("All required config keys present.")
    return not missing

def check_dirs():
    missing = [d for d in REQUIRED_DIRS if not Path(d).exists()]
    if missing:
        warn(f"Missing directories: {', '.join(missing)}")
    else:
        ok("All required directories exist.")
    return not missing

def check_files():
    missing = [f for f in REQUIRED_FILES if not Path(f).exists()]
    if missing:
        warn(f"Missing files: {', '.join(missing)}")
    else:
        ok("All required files exist.")
    return not missing

def run_diagnosis() -> None:
    cfg = load_cfg()
    results = [
        check_keys(cfg),
        check_dirs(),
        check_files(),
    ]
    if all(results):
        ok("Doctor check passed ‚Äî repo looks healthy.")
        sys.exit(0)
    warn("Doctor check failed ‚Äî fix the ‚ùå items above.")
    sys.exit(1)

if __name__ == "__main__":
    run_diagnosis()

##### <<< END FILE:   uberslicer/doctor.py <<< #####

##### >>> BEGIN FILE: uberslicer/patch.py <<< #####
import difflib
import uuid
import datetime
import os
import yaml
from pathlib import Path
from uberslicer.utils import CFG, log_dev, log_audit


def create_patch_block(oldfile: str, newfile: str, reason: str) -> None:
    """
    Create a YAML patch block by diffing OLD and NEW files.
    Writes output to the configured patch directory.
    """
    # Read file contents
    try:
        with open(oldfile, 'r') as f:
            old_lines = f.read().splitlines()
    except FileNotFoundError:
        old_lines = []
    try:
        with open(newfile, 'r') as f:
            new_lines = f.read().splitlines()
    except FileNotFoundError:
        new_lines = []

    # Generate unified diff
    diff = difflib.unified_diff(
        old_lines,
        new_lines,
        fromfile=oldfile,
        tofile=newfile,
        lineterm=""
    )
    content = "\n".join(diff)

    # Build the patch block
    block_id = f"patch-{uuid.uuid4()}"
    block = {
        "block_id": block_id,
        "session_metadata": {
            "timestamp": datetime.datetime.utcnow().isoformat(),
            "source": os.getcwd()
        },
        "tags": ["patch", "needs-review"],
        "content": content,
        "summary": reason,
        "patch_type": "diff"
    }

    # Ensure output directory exists
    patch_dir = CFG['paths']['patch_dir']
    Path(patch_dir).mkdir(parents=True, exist_ok=True)

    # Write YAML block
    outfile = Path(patch_dir) / f"{block_id}.yaml"
    with open(outfile, 'w') as f:
        yaml.dump(block, f, sort_keys=False)

    # Log and audit
    log_dev("patch", [f"{oldfile} -> {newfile}", reason])
    log_audit("info", f"Patch block created: {outfile}")
    print(f"[OK] Patch block written to {outfile}")

##### <<< END FILE:   uberslicer/patch.py <<< #####

##### >>> BEGIN FILE: uberslicer/ultraslicer.py <<< #####
#!/usr/bin/env python3
import os, sys, uuid, yaml, datetime
from uberslicer.utils import log_dev, log_audit

SCHEMA_FIELDS = [
    "session_metadata", "source", "block_id", "tags", "content",
    "summary", "map_refs", "decisions", "blockers", "meta_validation",
    "dopaminehit", "ritual_notes"
]

def ritual_header(block_id, summary):
    return {
        "block_id": block_id,
        "summary": summary,
        "ritual_notes": f"Ritual block created {datetime.datetime.utcnow().isoformat()}Z"
    }

def slice_blocks(input_path):
    with open(input_path) as f: raw = f.read()
    blocks = [b.strip() for b in raw.split('\n\n') if b.strip()]
    ritual_blocks = []
    for i, content in enumerate(blocks):
        block_id = f"block-{uuid.uuid4()}"
        ritual = {
            **ritual_header(block_id, f"UltraSlice {i+1}"),
            "session_metadata": {
                "timestamp": datetime.datetime.utcnow().isoformat(),
                "source_file": os.path.basename(input_path)
            },
            "source": input_path,
            "tags": ["ultraslice", "auto", "needs-review"],
            "content": content,
            "map_refs": [],
            "decisions": [],
            "blockers": [],
            "meta_validation": [],
            "dopaminehit": ["auto"],
        }
        for k in SCHEMA_FIELDS:
            ritual.setdefault(k, None)
        ritual_blocks.append(ritual)
    return ritual_blocks

def dump_blocks(blocks, outdir):
    os.makedirs(outdir, exist_ok=True)
    for block in blocks:
        outpath = os.path.join(outdir, f"{block['block_id']}.yaml")
        with open(outpath, "w") as f:
            yaml.dump(block, f, sort_keys=False)

if __name__ == "__main__":
    if len(sys.argv) < 3:
        print("Usage: python dopemux_ultraslicer.py <input_file> <output_dir>")
        sys.exit(1)
    input_file, outdir = sys.argv[1:3]
    blocks = slice_blocks(input_file)
    dump_blocks(blocks, outdir)
    log_dev(f"ultraslice", details=[f"Sliced {len(blocks)} blocks from {input_file} to {outdir}"])
    log_audit("info", f"Sliced file {input_file} into {len(blocks)} blocks.")
    print(f"[OK] Sliced, tagged, and dumped {len(blocks)} ritual blocks to {outdir}.")

##### <<< END FILE:   uberslicer/ultraslicer.py <<< #####

##### >>> BEGIN FILE: uberslicer/utils.py <<< #####
import yaml
import os
import datetime
from pathlib import Path
import random

# ‚îÄ‚îÄ‚îÄ CLI SUPPORTING UTILITIES ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def load_config():
    """Load only the `dopemux` section from config.yaml at project root."""
    cfg_path = Path("config.yaml")
    if not cfg_path.exists():
        raise FileNotFoundError("config.yaml not found")
    full_cfg = yaml.safe_load(cfg_path.read_text())
    if "dopemux" not in full_cfg:
        raise KeyError("config.yaml missing top-level 'dopemux' key")
    return full_cfg["dopemux"]

def colorize(text, style):
    """Placeholder: color your text by style."""
    return text

def print_banner(cfg):
    """If `banner` is set in config, print it once at startup."""
    banner = cfg.get("banner")
    if banner:
        print(banner)

def dopamine_nudge(cfg):
    """Randomly emit one of the `nudges` defined in config."""
    nudges = cfg.get("nudges", [])
    if nudges:
        print(random.choice(nudges))
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

# Dev/audit logging helpers (unchanged)
DEVLOG_PATH = "üíäD√òPEM√úX-‚ò†Ô∏èUBERSLICER‚ò†Ô∏è‚ÄîTFE-DEVLOG.txt"
AUDIT_PATH  = "üíäD√òPEM√úX-‚ò†Ô∏èUBERSLICER‚ò†Ô∏è‚ÄîTFE-AUDIT-ULTRA-RITUAL.txt"

def _append_block(path, entry):
    entry['timestamp'] = datetime.datetime.utcnow().isoformat()
    if not os.path.exists(path):
        with open(path, "w") as f: yaml.dump({'entries': [entry]}, f)
    else:
        with open(path) as f: data = yaml.safe_load(f) or {}
        entries = data.get('entries', [])
        entries.append(entry)
        with open(path, "w") as f: yaml.dump({'entries': entries}, f)

def log_dev(action, details=None):
    block = {'action': action, 'details': details or []}
    _append_block(DEVLOG_PATH, block)

def log_audit(level, summary):
    block = {'level': level, 'summary': summary}
    _append_block(AUDIT_PATH, block)

# ‚îÄ‚îÄ‚îÄ GLOBAL CONFIG REFERENCE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
CFG = load_config()

##### <<< END FILE:   uberslicer/utils.py <<< #####

##### >>> BEGIN FILE: uberslicer/validator.py <<< #####
from pydantic import BaseModel, ValidationError
import yaml, json, sys, glob
from pathlib import Path
from uberslicer.utils import log_audit, CFG

SCHEMA_PATH = Path(CFG["schema"]["file"])
SCHEMA = json.loads(SCHEMA_PATH.read_text())

class UltraBlock(BaseModel):
    project: str
    block_id: str
    session_metadata: dict
    content: str
    tags: list
    summary: str | None = None
    patch_type: str | None = None  # only for patch blocks

def validate_all():
    """
    Validate every YAML block under the tagged folder against the UltraBlock schema,
    and also catch any 'patch' blocks still carrying the 'needs-review' tag.
    """
    paths = glob.glob(f"{CFG['paths']['tagged']}/**/*.yaml", recursive=True)
    bad, pending = 0, 0

    for p in paths:
        try:
            data = yaml.safe_load(open(p))
            UltraBlock(**data)  # will raise on invalid schema
            if "patch" in data.get("tags", []) and CFG["auditor"]["block_review_tag"] in data.get("tags", []):
                pending += 1
        except ValidationError as e:
            log_audit("error", {"file": p, "errors": e.errors()})
            bad += 1

    if bad or pending:
        sys.exit(f"‚ùå validation failed: {bad} bad blocks, {pending} pending patches")
    print("‚úÖ all blocks validated & no pending patch review")

##### <<< END FILE:   uberslicer/validator.py <<< #####

